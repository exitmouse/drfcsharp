We initially decided to use a graph min-cut algorithm to classify from
a trained model, but ran into problems with classifying the entire
image the same way. At first, we thought this was a problem with the
inter-site weights. However, after our milestone presentation, in
which we explained the problem we were having, we went over the
mathematical derivation we had used to calculate the correct edge
weights and discovered it was wrong.

We had followed the explanation of the method in Kumar and Hebert's
paper, but this explanation was extremely terse, and it turned out
that our best guess as to what it meant was wrong. Kumar and Hebert
themselves used min-cut code supplied by a colleague of theirs who has
done extensive work specifically in using graph-cut algorithms to
estimate MRF likelihoods.

So, we tried for a long while to rederive edge weights that resulted
in the correct equivalence between the capacity of a cut on the graph
and the negative likelihood of a classification, but we ran into
problems for two reasons.

The edge weights are allowed to depend on the specific image and
parameters of the model, but they are not allowed to depend on the
classification. Initially, our main problem was an inability to
express the association potential of the DRF model in this way; we
think, however, that we did it, by consulting papers from Kumar and
Hebert's colleague Vladimir Kolmogorov rather than the papers Kumar
and Hebert cited.

However, we still ran into the problem of negative edge weights. The
association potential in this model is the log of a probability, and
so is always negative, and we couldn't figure out a way to make it
work.
