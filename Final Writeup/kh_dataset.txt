In addition to working with our own dataset of aerial orthophotos, we also
wanted to test our algorithm implementation on datasets from other authors.

Shortly before the Milestone, we contacted Sanjiv Kumar who kindly provided 
us with a copy of the 237 image set that he and Hebert used for their 
man-made structure detection implementation.  This dataset consists of 
108 training images and 129 test images, all drawn from the Corel photo
database.  Each image in this set has one axis with a length of 384 pixels
and another axis with a length of 256 pixels, though some of the images were
in landscape orientation, and some were in portrait orientation.

Along with each image, Kumar and Hebert had stored their site labelings 
as pairs of 24 by 16 pixel black and white tiff images.  One of the label images 
uses white pixels to label sites that contain "edgy structure" sections.  
The other label image corresponding to the same photo stores labels
for sites that contain "smooth structure" sections.  According to the supplied
documentation, for the man-made structure detection task, Kumar and Hebert
combined these two labels into a single boolean structure label using 
a logical or operation.

We wrote some single time execution scripts (saved in KumarAndHebertLabelConverter/)
to load each of the tiff labeling files provided by Kumar and Hebert, 
perform the desired combination, and then save the output as a comma-separated-values 
labeling file of the type that we have been using with our algorithm implementation.
After then reflecting each of the portrait orientation images to landscape 
orientation, and then modifying out DRF implementation and DataLabeler to
accept images with 24x16 sites, we were able to train our DRF model on 
Kumar and Sanjivs data.