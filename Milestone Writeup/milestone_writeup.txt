Image Features:

We have implemented the single-scale image features from [DRFS 2006]
because they are most useful for comparison with other methods; we
should be able to implement the multi-scale features with little
additional trouble later.

The image features are all derived from an initial pixel-by-pixel
gradient computation. To calculate the gradient vector at a pixel, we
first convert the image to grayscale using NTSC-recommended values
($\text{Intensity} = 0.299*R + 0.587*G + 0.114*B$). Then to get the directional
x-derivative, we convolve the resultant matrix of intensities with the
derivative of a gaussian horizontally and the original gaussian
vertically; the process is analogous for the directional
y-derivative. We wrote code in C# to do this; we found no library to
do it for us.

The variance of the gaussian is a hyper-parameter; we will have to
optimize it. For now, we contacted Kumar and Hebert and they say they
used 0.5 which seems like a decent, upstanding number that we don't
really object to much. The algorithm is coded referencing the number
only as a constant, so we can change it easily.

We bin the gradients into a histogram array indexed by orientations;
we weight their contributions by their L2 norms. We chose to smooth
the histogram with a simple triangular kernel, rather than the
gaussian kernel of [DRFS 2006]; this will be very simple to change
later.

The number of bins in the histogram is also a hyper-parameter; we can
change it in the code by editing one variable. We chose 8 bins as a
preliminary step, based on our research from [SZELISKI BOOK]

Then the features we compute are heaved central-shift moments $v_p$ of
the $0$th through $2$nd order. $v_0$ is defined as the arithmetic mean
of the magnitudes. Let the bins be $E_i$ and let $H(x)$ be the
indicator function for the positive real numbers; then $v_p$ for $p >
0$ is defined as 

\[ 
\frac{\sum_i (E_i-v_0)^{p+1}H(E_i-v_0)}{\sum_i
(E_i-v_0)H(E_i-v_0)}.  
\]

In addition, we compute the absolute value of the sine of the angle
difference between the two highest peaks of the histogram, to measure
the presence of near-right-angle junctions.

In the original [DRFS 2006] paper, Kumar and Hebert also used the
angle of the highest peak to perhaps allow their algorithm to catch on
to the predominance of vertical lines in man-made structures in their
data-set. However, our photos are not taken from upright cameras,
houses did not tend to be aligned with the cameras, and in fact we
randomly rotated the images in preprocessing to enforce this
invariance, so we removed this feature. It should not be useful for
our application; it would function as random noise.

As we said earlier, we only coded the single-site feature vector, but
the remaining features from [DRFS 2006] were all simple functions of
the pixel-wise gradient histograms, so we will be able to implement
them if necessary.

Modified model:

We decided to use the modified DRF model presented in [DRFS 2006], as
the learning objective is convex and it promised to be slightly easier
to train. Kumar and Hebert suggest gradient ascent to maximize the
log-likelihood, but we had to rederive the gradients with respect to
the vector parameters of the model.

In exchange, however, the algorithm for inference became slightly more
technical. We were planning on using iterated conditional modes;
iterating over the image assigning to each site the label of maximum
likelihood given its neighbors. With the modified DRF model, though,
you can compute exact MAP estimates of the labeling with an algorithm
presented in [FOX/NICHOLS/GRIEG] as mentioned in [DRFS 2006].

Training:

[GRADIENT DERIVATION]

Issues with the training:
We had trouble for a while getting 
